{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We use this notebook to manually guide the operation of splitting the recordings into 5 sec chunks. \n",
    "The change is split into three steps:\n",
    "1. Reading the original Dataset.\n",
    "2. Splitting the files into fixed-size audios.\n",
    "3. Reading back the new \n",
    "\n",
    "It should be noted that the 'Dataset' object does not read into memory the files, rather it loads the metadata _csv_: reading the whole data at once would be useless and unfeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we load the dataframe of the dataset, with the `metadata == True`, which allows us to split the recordings based on audio length. Moreover, setting parameter `feature_mode=''`, we ensure that the audio is simply split, while preserving its format: although we first considered saving the Mel Spectrograms directly, to avoid computing it at every training step, we opted to use CUDA to speed up computation, as saving the whole data would have taken 50 GB, surpassing our memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_params = {'sample_rate': 32000, 'n_fft': 1024, 'hop_length': 501, 'n_mfcc': 128, 'n_mels': 128, 'feature_size': 2048}\n",
    "\n",
    "df = AudioDataset(\n",
    "    datafolder=\"data\",\n",
    "    metadata_csv=\"train.csv\",\n",
    "    audio_dir=\"train_audio\",\n",
    "    feature_mode='',\n",
    "    audio_params=audio_params,\n",
    "    metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the AudioDataset into shorter files, with a new '.csv' index and 'train_audio' directory is that it allows us to access a relevant section of the recording directly, without reading the complete file from memory. We perform the , which can be reused by loading the data directly to the gpu, without reprocessing every time, which is a major bottleneck to training.\n",
    "\n",
    "In order to test the code before shipping it to the queue, we also preprocess a fraction of the data, on which we run our scripts as a preliminary step. Naturally, due to the nature of the cluster, we also maintain two different sets conda environments, which we track using 'yml' files: one for our local devices and the other for our partition in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust as fit, to export more data\n",
    "df.data = df.data.head(1000)\n",
    "df.preprocess(output='train_proc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed data is read back into memory to ensure that the operation was successful. We use this snippet to examine the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_params = {'sample_rate': 32000, 'n_fft': 1024, 'hop_length': 501, 'n_mfcc': 128, 'n_mels': 128, 'feature_size': 2048}\n",
    "\n",
    "dataset = AudioDataset(\n",
    "    datafolder=\"data\",\n",
    "    metadata_csv=\"train_proc.csv\",\n",
    "    audio_dir=\"train_proc\",\n",
    "    feature_mode='mel',\n",
    "    audio_params=audio_params,\n",
    "    metadata=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we quantify the loss of data driven by dropping audios of length <2.5 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "(dataset.data['duration'] % 5).hist(bins=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef",
   "language": "python",
   "name": "birdclef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
