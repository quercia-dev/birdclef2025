{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838041fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_data import *\n",
    "from utility_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import time\n",
    "\n",
    "print(\"Imported libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c9b3d",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(\n",
    "    datafolder=\"data\",\n",
    "    metadata_csv=\"train_proc.csv\",\n",
    "    audio_dir=\"train_proc\",\n",
    "    feature_mode=''\n",
    ")\n",
    "\n",
    "print(dataset[0][0].size())\n",
    "\n",
    "print(\"Initialised Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e1cb2",
   "metadata": {},
   "source": [
    "## Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c430179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelCNN(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int, learning_rate: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # input size: [B, 1, 128, 320]\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # [B, 32, 128, 320]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),            # [B, 32, 64, 160]\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # [B, 64, 64, 160]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),            # [B, 64, 32, 80]\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), # [B, 64, 32, 80]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # global avg pool to avoid large FC layer\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),           # [B, 64]\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_pool(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate, weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "    \n",
    "print(\"Defined Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c34d0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9952b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=7, persistent_workers=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, num_workers=7, persistent_workers=True)\n",
    "print(\"Constructed training data infrastructure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MelCNN(num_classes=len(dataset.classes))\n",
    "\n",
    "logger = TensorBoardLogger('tb_logs', name='melcnn')\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=3,\n",
    "    filename='{epoch}-{val_loss:.2f}'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10, \n",
    "    callbacks=[checkpoint_callback], \n",
    "    logger=logger, \n",
    "    log_every_n_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a097c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beginning training\")\n",
    "\n",
    "start = time.time()\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "print(f\"Execution time: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1434226",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_log('lightning_logs/version_0/metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef",
   "language": "python",
   "name": "birdclef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
